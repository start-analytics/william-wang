import requests
import json
import io
from bs4 import BeautifulSoup
from PIL import Image

def fetch_instagram_data(instagram_url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    # å‘é€è¯·æ±‚è·å– Instagram é¡µé¢
    response = requests.get(instagram_url, headers=headers)
    if response.status_code != 200:
        print("âŒ Failed to retrieve the page. Make sure the URL is correct and Instagram allows access.")
        return None

    # è§£æ HTML
    soup = BeautifulSoup(response.text, "html.parser")

    # æå–å›¾ç‰‡
    image_blobs = []
    images = soup.find_all("img")

    for img in images:
        img_url = img.get("src")
        if img_url:
            try:
                img_response = requests.get(img_url)
                img_blob = io.BytesIO(img_response.content)
                image_blobs.append(img_blob.read())  # ä»¥äºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨å›¾ç‰‡
            except Exception as e:
                print(f"âš ï¸ Failed to download image: {img_url}, Error: {e}")

    # æå–è¯„è®ºï¼ˆå¯èƒ½å­˜åœ¨äº <span> æˆ– <p> æ ‡ç­¾ä¸­ï¼‰
    comments = []
    for comment in soup.find_all("span"):
        text = comment.get_text().strip()
        if text:
            comments.append(text)

    # ç»„ç»‡ JSON æ•°æ®
    output_data = {
        "blobs": image_blobs,
        "comments": comments
    }

    return output_data

# è¿è¡Œçˆ¬è™«
if __name__ == "__main__":
    insta_url = input("ğŸ”— è¯·è¾“å…¥ Instagram å¸–å­é“¾æ¥: ")  # è®©ç”¨æˆ·è¾“å…¥å¸–å­ URL
    data = fetch_instagram_data(insta_url)

    # ä¿å­˜ JSON æ•°æ®
    if data:
        with open("instagram_data.json", "w") as f:
            json.dump({"blobs": [blob.hex() for blob in data["blobs"]], "comments": data["comments"]}, f)
        print("âœ… Data saved successfully to instagram_data.json")
    else:
        print("âŒ No data fetched.")
